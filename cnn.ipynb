{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard,EarlyStopping\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define a learning rate scheduler that starts with a learning rate of 0.001 and reduces it by 5% after each epoch\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "MildDemented_dir = r'/Users/aryan/Downloads/Synopsys_data/40k/AugmentedAlzheimerDataset/MildDemented'\n",
    "ModerateDemented_dir = r'/Users/aryan/Downloads/Synopsys_data/40k/AugmentedAlzheimerDataset/ModerateDemented'\n",
    "NonDemented_dir = r'/Users/aryan/Downloads/Synopsys_data/40k/AugmentedAlzheimerDataset/NonDemented'\n",
    "VeryMildDemented_dir = r'/Users/aryan/Downloads/Synopsys_data/40k/AugmentedAlzheimerDataset/VeryMildDemented'\n",
    "\n",
    "filepaths = []\n",
    "labels = []\n",
    "dict_list = [MildDemented_dir, ModerateDemented_dir, NonDemented_dir, VeryMildDemented_dir]\n",
    "class_labels = ['Mild Demented', 'Moderate Demented', 'Non Demented', 'Very MildDemented']\n",
    "\n",
    "for i, j in enumerate(dict_list):\n",
    "    flist = os.listdir(j)\n",
    "    for f in flist:\n",
    "        fpath = os.path.join(j, f)\n",
    "        filepaths.append(fpath)\n",
    "        labels.append(class_labels[i])\n",
    "\n",
    "Fseries = pd.Series(filepaths, name=\"filepaths\")\n",
    "Lseries = pd.Series(labels, name=\"labels\")\n",
    "Alzheimer_data = pd.concat([Fseries, Lseries], axis=1)\n",
    "Alzheimer_df = pd.DataFrame(Alzheimer_data)\n",
    "print(Alzheimer_df.head())\n",
    "print(Alzheimer_df[\"labels\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alzheimer_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images = train_test_split(Alzheimer_df, test_size=0.3, random_state=42)\n",
    "train_set, val_set = train_test_split(Alzheimer_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set.shape)\n",
    "print(test_images.shape)\n",
    "print(val_set.shape)\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(preprocessing_function= tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "train = image_gen.flow_from_dataframe(dataframe= train_set,x_col=\"filepaths\",y_col=\"labels\",\n",
    "                                      target_size=(244,244),\n",
    "                                      color_mode='rgb',\n",
    "                                      class_mode=\"categorical\", #used for Sequential Model\n",
    "                                      batch_size=32,\n",
    "                                      shuffle=False            #do not shuffle data\n",
    "                                     )\n",
    "test = image_gen.flow_from_dataframe(dataframe= test_images,x_col=\"filepaths\", y_col=\"labels\",\n",
    "                                     target_size=(244,244),\n",
    "                                     color_mode='rgb',\n",
    "                                     class_mode=\"categorical\",\n",
    "                                     batch_size=32,\n",
    "                                     shuffle= False\n",
    "                                    )\n",
    "val = image_gen.flow_from_dataframe(dataframe= val_set,x_col=\"filepaths\", y_col=\"labels\",\n",
    "                                    target_size=(244,244),\n",
    "                                    color_mode= 'rgb',\n",
    "                                    class_mode=\"categorical\",\n",
    "                                    batch_size=32,\n",
    "                                    shuffle=False\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=list(train.class_indices.keys())\n",
    "print (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_brain_images(image_gen):\n",
    "    test_dict = test.class_indices\n",
    "    classes = list(test_dict.keys())\n",
    "    images, labels=next(image_gen) # get a sample batch from the generator\n",
    "    plt.figure(figsize=(20,20))\n",
    "    length = len(labels)\n",
    "    if length<25:\n",
    "        r=length\n",
    "    else:\n",
    "        r=25\n",
    "    for i in range(r):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        image=(images[i]+1)/2 #scale images between 0 and 1\n",
    "        plt.imshow(image)\n",
    "        index=np.argmax(labels[i])\n",
    "        class_name=classes[index]\n",
    "        plt.title(class_name, color=\"green\",fontsize=16)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_brain_images(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(8, 8), strides=(3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3, 3)),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(1, 1), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(1, 1), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1024, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1024, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.optimizers.SGD(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train, epochs=20, validation_data=val, validation_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)\n",
    "pred = np.argmax(pred, axis=1) #pick class with highest  probability\n",
    "\n",
    "labels = (train.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred2 = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "y_test = test_images.labels # set y_test to the expected output\n",
    "print(classification_report(y_test, pred2))\n",
    "print(\"Accuracy of the Model:\",\"{:.1f}%\".format(accuracy_score(y_test, pred2)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = ['Mild Demented', 'Moderate Demented', 'Non Demented', 'Very MildDemented']\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, pred2)\n",
    "\n",
    "# Create a figure and plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues')\n",
    "\n",
    "# Set tick labels and axis labels\n",
    "plt.xticks(ticks=[0.5, 1.5, 2.5, 3.5], labels=class_labels)\n",
    "plt.yticks(ticks=[0.5, 1.5, 2.5, 3.5], labels=class_labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "\n",
    "# Set the title\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asdrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
